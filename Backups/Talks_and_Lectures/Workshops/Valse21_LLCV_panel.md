# Valse 2021 底层视觉与图像处理Panel  

2023/2/19  

* 五个议题：  
    * 存不存在可用于多种IR任务的模型（这也算问题）？  
    * 有什么提升IR任务的性能/技巧，是数据问题还是算法问题？  
    * 如何评价图像质量；  
    * LLCV和HLCV的互动不很多，LLCV一定可以促进HLCV的性能嘛？  
    * 如何满足LLCV的实时性需求？  
    ![](https://raw.githubusercontent.com/YouCaiJun98/MyPicBed/main/imgs/20230219173331.png)  

## Topic1: LLCV Universal Model  
* 戴玉超：  
    * 目前有这种工作；不同任务的物理/数学模型差异较大，训练这种模型的数据要求较高（不是一个很好的思路）；  
    * 同一个结构，不同任务上的训练可以；  
    * 和物理/数学模型结合（不太认可）；  

* 张乐飞：  
    * 做可以，但很难做到最好；  
    * 不同任务中的处理思路（例如循环处理）可以相互借鉴；  

* 郭晓杰：  
    * 可以但是有困难；  
    * 任务之间存在多样性、顺序上存在差异也会让问题的复杂度变高 -> **模型会变得非常庞大** -> 数据也会变得很多 -> 模型的训练也会难（速度、稳定性）；

* 许翔宇：  
    * 难度很大（本来就很难，若干问题叠加在一起更难）；没有必要性（很少出现同时有若干degredation的情况）；  
        * 感觉有点离题了，我理解应该是同一模型处理多个单降质过程；    

## Topic2: Image Restoration Technique  
问题：有哪些提升模型性能的技巧、目前bound在哪里、有什么可以新研究的方向  
* 戴玉超：  
    * 新的研究方向：  
        * 面向新型传感器（事件相机等）；  
    * 提高性能：  
        * 多维度（算法、数据等共同约束）；**如何获得更真实的数据**（同意）  

* 张乐飞：  
    * 从目前的评价指标来看，目前的图像处理精度已经很高了，很难再有发展；  
    * 琐碎：自动预测修补的mask、如何鉴别原始图像/被修补图像（被其他老师喷了说有人做过）  

* 郭晓杰：  
    * 从高层语义引导做底层图像的处理；  
    * 数据和算法都很关键；但是算法更关键（不同意，而且他的论点是，数据更重要的话算法工作就没有意义了）；    

* 许翔宇：  
    * 数据和算法都重要；  
    * unsupervised方法研究；  

## Topic3: Image Quality Assessment  
Q：主观评价和客观评价存在gap，如何减少这种差异  
* 戴玉超：  
    * 不用缩小主客观评价的差距，要看服务的客体是谁，人 or 机器；  
        * 人：让loss和主观指标一致（正确的废话）；如何更好地利用相对较少的主观标定数据；  
        * 机器：看下游任务；  

* 张乐飞：  
    * 赞同戴老师；可以不一致，主要看下游任务；  

* 郭晓杰：  
    * 目前的客观评价和主观评价之间有较大差距；且指标之间就有很大差异，关注不同地方（PSNR与SSIM）；  
    * 任务之间也有差异，去噪任务可以有gt，增强任务没有gt，更不好评价；  
    * 引入user study，避免身边人bias；建立双盲第三方、主观评价；  

* 许翔宇：  
    * 目前来看取决于应用场景；  
        * fidelity -> PSNR, SSIM;  
        * 娱乐 -> 主观指标；  
    * 有参定量&无参定量：  
        * 期待未来工作...  

## Topic4: 底层视觉是否能促进高层视觉  
* 戴玉超：  
    * 底层视觉不一定能促进高层视觉效果，与场景、数据相关（缺少数据）；  
    * 要做case study；  

* 张乐飞：  
    * 不一定会促进；高层任务可能已经考虑了低质数据的问题（LLCV处理后数据的分布可能有bias）；    

* 郭晓杰：  
    * 没尝试过，直接接应该会更差；  
        * 分布的角度；  
        * 不同评价指标下可能会有不同结果；  
    * 反过来，高层 -> 底层可能有帮助；  

* 许翔宇：  
    * 有过尝试，没有帮助（甚至更差）；  
    * 传统时代有帮助，DL时代没帮助 -> 图像分布、end2end（训练时loss之间的冲突）；  

## Topic5: LLCV高效性  
* 戴玉超：  
    * 依赖于通用网络设计的进步（直接迁移高层任务的高效方法）；  
    * 结合任务特性，手工设计高效网络；  
    * 利用输入之间的时序依赖；  

* 张乐飞：  
    * 没有好想法；  

* 郭晓杰：  
    * 传统优化框架 + 深度特征提取 + NAS （？？？在说什么）  


* 许翔宇：  
    * 没有好想法；  
    * 剪枝 / 蒸馏等通用压缩方法；  
    * NN + 传统方法结合；  

