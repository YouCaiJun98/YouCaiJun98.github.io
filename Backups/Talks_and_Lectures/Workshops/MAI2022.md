# MAI2022记录  

2022/6/30  

## Intro：Deep Learning on Mobile Devices:  What's New in 2022?  
1. 部署的两种选择  
* Android NN API：  
    * pros：API调用形式，硬件层blind，不用自己考虑底层硬件，会自动选择并加速  
    * 依赖硬件提供商的driver  
    ![](https://raw.githubusercontent.com/YouCaiJun98/MyPicBed/main/imgs/202206300001.png)  
    
    * con 1：NNAPI HAL碎片化现象严重  
    ![](https://raw.githubusercontent.com/YouCaiJun98/MyPicBed/main/imgs/20220630195834.png)  
        * 生态很差，各种driver和版本各行其道（api难对齐；可能有bug；结果不一致）  
    
    * con 2：只支持一定数量的TFLite op  

* TensorFlow Lite Delegate：  
    * 本质上是vendor给不同soc提供的lib？  
    * pros：
        * 使用便捷，只需要把binary lib粘到proj（还是其他什么地方）里？  
        * 独立于Android OS sys （version），能在任何支持OpenCL的GPU上加速推理，对于一些古老机型也能有用  
        * 大多数架构都能加速，能支持大模型（上GB的ram）    

* Pytorch Mobile：  
    * op覆盖广；CPU加速效果明显；依赖于NNAPI；不太推荐  

2. 推理类型  
* 不同推理类型  
    * FP32  
        * balabala...1符号位+8指数位+23分数位；NPU不支持FP32  
    * FP16  
        * 1符号位+5指数位+10分数位；在所有mobile lib中FP32->FP16自动发生；  
    * Int8  
        * 几乎对所有硬件都能加速推理，减少RAM消耗，提高能效；许多mobile NPU只支持Int    推理；  
            * 在图像分类任务中works well  
            * 在SR这类简单的图像处理任务重works so-so  
            * 在ISP&NLP中不work  
        * 一些Int8类型  
            * Dynamic range quantization: 精度高，没加速效果  
                * 伪量化（参数从int换回float再运算）
            * Full integer quantization: 精度高，没加速效果      
                * 输入输出和一些op没有量化  
            * Integer only：精度最低但是能在所有INT8的NPU上跑    
    * Int16  
        * FP16的良好替代，尺寸不变但是可以整数推理；  
        * 没有显著的精度问题，适合图像处理；  
        * 许多NPU不支持，TFLite不支持；  

* 一些chipset  
    * Qualcomm Chipsets  
        * Classic Hexagon DSPs  
        * Hexagon Tensor Processor（HTP）  
        * Hexagon Tensor Processor（HTP）v2  
        * Qualcomm Hexagon TFLite Delegate 
            * 支持所有含有classic NN-Compatible Hexagon DSP的Qualcomm SoC  
            * op支持覆盖比NNAPI好  
            * 任务性能好  
            * 一些厂商不允许外部调用Hexagon DSP；即将被弃用；  
        * （看起来是升级版）Qualcomm QNN TFLite Delegate  
            * 支持带Hexagon HTP的Qualcomm SoC；支持Qualcomm Adreno GPU的推理；  
            * op支持和覆盖好；runtime result好；有很多performance & power   consumption   的trade-off选项；  
            * 但是经典Hexagon DSP的支持还不到位，即将不支持老版的Hexagon DSP  
    * MediaTek Chipsets  
        * MediaTek Neuron TFLite Delegate  
    * Samsung Chipsets  
    * Huawei Chipsets  
    * Google Chipsets  
    * 总结：  
        * 大部分没有NPU  

3. Benchmark  
4. IOS 生态  
* AI hardware的一些关键要素  
    * 计算资源（TOPs/TFLOPS, etc.）  
    * 支持不同推理类型（FP16, INT8, ...）  
    * 支持op  
* TensorFlow Lite CoreML Delegate 
5. Burnout  

## Talk1: Mobile AI Trend and Power Performance Metric  
by Allen Lu, Jimmy Chiang from Mediatek  
* Mobile AI application Evolution  
列了个发展趋势，挺有意思的：  
* 2017-2018 Perception - Face Unlock  
* 2018-2019 Construction - Photo bokeh（背景虚化）  
* 2019-2020 Quality - Image noise reduction（原来这个已经过时了？）  
* 2020-2022 Motion - Video & Game frame rate conversion(加上时间轴，计算量++，比如插帧)  
* 2023-2025 depth - VR & MR 3D interaction  
![](https://raw.githubusercontent.com/YouCaiJun98/MyPicBed/main/imgs/20220630224029.png)  








    
