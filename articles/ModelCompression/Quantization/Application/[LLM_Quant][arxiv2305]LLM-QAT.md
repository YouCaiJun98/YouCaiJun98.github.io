# LLM-QAT: Data-Free Quantization Aware Training for Large Language Models  

2023/10/16  

来源：arxiv2305    
resource：[github上备份](https://github.com/YouCaiJun98/MyLibrary/blob/main/articles/ModelCompression/Quantization/%5BLLM%20Quant%5D%5Barxiv2305%5DLLM-QAT.pdf)的包括ipad标注的pdf版本。  
